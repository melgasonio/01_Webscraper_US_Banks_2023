{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d014b02",
   "metadata": {},
   "source": [
    "## Welcome\n",
    "This is a simple webscraping project that summarizes U.S. banks data in 2023 into a single dataset. I used a website called ***US Bank Locations*** (https://www.usbanklocations.com/). These are the processes involved in this project:\n",
    "1. Importing libraries necessary for the execution of this program.\n",
    "2. Inspecting the webpages to correctly identify target elements.\n",
    "3. Scraping the webpages.\n",
    "4. Transforming the scraped data into dataframes.\n",
    "5. Merging the dataframes into a single dataframe and exporting it as a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5793ba",
   "metadata": {},
   "source": [
    "**Importing libraries**\n",
    "\n",
    "* ***requests*** - sends HTTP request.  \n",
    "* ***BeatifulSoup*** - parses HTML.  \n",
    "* ***pandas*** - transforms scraped data into a dataframe, combines multiple dataframes into a single dataframe, exports the dataframe into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc6c6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612f4dc",
   "metadata": {},
   "source": [
    "* ***base_url*** is the url of the website's homepage.\n",
    "* ***response*** is the HTTP response.\n",
    "* ***soup*** is the assigned variable of response's parsed html.\n",
    "* ***divs*** is a list of all elements with HTML div tag.\n",
    "* ***divs[13]*** is the division element with the desired anchor elements containtaining their respective href attributes.\n",
    "* ***hrefs*** is a list of all href attributes of anchor elements in *divs[13]*.\n",
    "* The for loop in **line 9** iterates through the *hrefs* list. The ***final_link*** variable is defined as a concatenation of *base_url* and the href attribute of a particular anchor element at a time.\n",
    "* Also, the ***final_link*** is appended to the ***links*** list in the loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6d3a4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.usbanklocations.com/' #used to scrape elements with href attributes\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "divs = soup.find_all('div')\n",
    "#print(divs[13])\n",
    "links = []\n",
    "hrefs = divs[13].find_all('a', href=True)\n",
    "for a in hrefs:\n",
    "    final_link = base_url+a['href']\n",
    "    links.append(final_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6f5ff",
   "metadata": {},
   "source": [
    "* The ***scrape(link)*** function is a function that takes *link* as an argument and has a return value of a dataframe. \n",
    "* Inside it, ***column1*** and ***column2*** lists are initially set to be empty. The argument ***link*** is passed on to the get() method to make a response, which then is parsed and stored as the ***soup*** variable.   \n",
    "* Also, we have ***tables*** and ***rows*** as the lists of elements with tags *table* and *tr* in *tables[1]*, respectively.  \n",
    "* The rows of ***tables*** are iterated over by a for loop, from its second row to the last. \n",
    "* The ***attribute_value*** and ***bank_name*** variables are defined and appended to the lists defined above. \n",
    "* The dataframe, in which the ***columns1*** and ***columns2*** lists stand as values of keys, is defined as the ***dataframe*** variable.\n",
    "* **Duplicate rows** with the same bank names are dropped from ***dataframe***.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6738e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def a scrape funtion\n",
    "def scrape(link):\n",
    "    column1 = []\n",
    "    column2 = []\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    rows = tables[1].find_all('tr')\n",
    "    for i in range(1, len(rows)):\n",
    "        cells = rows[i].find_all('td')\n",
    "        attribute_value = cells[1].text\n",
    "        bank_name = cells[2].text\n",
    "        column1.append(bank_name)\n",
    "        column2.append(attribute_value)\n",
    "    \n",
    "    att_row = rows[0].find_all('td')\n",
    "    attribute_name = att_row[1].text\n",
    "    table = {'Bank':column1, attribute_name:column2}\n",
    "    dataframe = pd.DataFrame(data=table).drop_duplicates('Bank', keep='first')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b888f73f",
   "metadata": {},
   "source": [
    "* ***dataframes*** is an initially empty list which will eventually be the list of all dataframes.\n",
    "* The for loop calls for the ***scrape*** function and appends the resulting dataframe at a time to the *dataframes* list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a5f14765",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for link in links:\n",
    "    dataframes.append(scrape(link))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e73fe8",
   "metadata": {},
   "source": [
    "* ***merged_df*** is defined to be the concatenation of all dataframes. The **'Bank'** column is the set to be the index, which was the reference of merging the dataframes.  \n",
    "* A column named ***'Id'*** is added, which stands as a unique identifier of a bank in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d382e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df.set_index('Bank') for df in dataframes], ignore_index=False, axis=1)\n",
    "merged_df.insert(0, 'Id', range(1, 1+(len(merged_df))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e109b4f",
   "metadata": {},
   "source": [
    "The final data set is exported as a csv file with a file name of ***US_Bank_2023_Dataset.csv***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "31acff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('US_Bank_2023_Dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
